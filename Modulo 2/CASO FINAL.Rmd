---
title: "Caso Pŕactico Final"
output:
  pdf_document: default
  html_notebook: default
  html_document: default
---

Tomaremos el dataset de aprobación de crédito bancario en https://archive.ics.uci.edu/ml/datasets/Credit+Approval . Los datos también se pueden cargar de la carpeta de contenido en  `crx.data`. La información del dataset está en https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.names y expone lo siguiente:

      1. Title: Credit Approval

      2. Sources: 
          (confidential)
          Submitted by quinlan@cs.su.oz.au
      
      3.  Past Usage:
      
          See Quinlan,
          * "Simplifying decision trees", Int J Man-Machine Studies 27,
            Dec 1987, pp. 221-234.
          * "C4.5: Programs for Machine Learning", Morgan Kaufmann, Oct 1992
        
      4.  Relevant Information:
      
          This file concerns credit card applications.  All attribute names
          and values have been changed to meaningless symbols to protect
          confidentiality of the data.
        
          This dataset is interesting because there is a good mix of
          attributes -- continuous, nominal with small numbers of
          values, and nominal with larger numbers of values.  There
          are also a few missing values.
        
      5.  Number of Instances: 690
      
      6.  Number of Attributes: 15 + class attribute
      
      7.  Attribute Information:
      
          A1:	b, a.
          A2:	continuous.
          A3:	continuous.
          A4:	u, y, l, t.
          A5:	g, p, gg.
          A6:	c, d, cc, i, j, k, m, r, q, w, x, e, aa, ff.
          A7:	v, h, bb, j, n, z, dd, ff, o.
          A8:	continuous.
          A9:	t, f.
          A10:	t, f.
          A11:	continuous.
          A12:	t, f.
          A13:	g, p, s.
          A14:	continuous.
          A15:	continuous.
          A16: +,-         (class attribute)
      
      8.  Missing Attribute Values:
          37 cases (5%) have one or more missing values.  The missing
          values from particular attributes are:
      
          A1:  12
          A2:  12
          A4:   6
          A5:   6
          A6:   9
          A7:   9
          A14: 13
      
      9.  Class Distribution
        
          +: 307 (44.5%)
          -: 383 (55.5%)
      
## Actividades a realizar

1. Carga los datos. Realiza una inspección por variables de la distribución de aprobación de crédito en función de cada atributo visualmente. Realiza las observaciones pertinentes. ¿ Qué variables son mejores para separar los datos?

```{r}
library(ggplot2)
cred <- read.csv("CASO_FINAL_crx.data", header = FALSE, na.strings = "?")
str(cred)

histograma <- function(x) {
  min <- min(x, na.rm = TRUE)
  max <- max(x, na.rm = TRUE)
  media <- mean(x, na.rm = TRUE)
  mediana <- median(x, na.rm = TRUE)
  dt <- sd(x, na.rm = TRUE)
  
  hist(x, freq = F)

  lines(density(x, na.rm = TRUE),
        lwd = 2,
        col = "chocolate3")
  
  abline(v = media,
         col = "royalblue",
         lwd = 2)
  
  abline(v = mediana,
         col = "red",
         lwd = 2)
  
  legend(
    x = "topright",
    c("Density plot", "Mean", "Median"),
    col = c("chocolate3", "royalblue", "red"),
    lwd = c(2, 2, 2)
  )
}
```

```{r}
tbl = table(cred$V1, cred$V16)
tbl

chisq.test(tbl)

ggplot(cred, aes(V1, fill=V16)) + geom_bar()
```
El resultado de este chi square parece muy bueno: p-value = 0.5769
En el gráfico de barras se ve una mayor frecuencia sobre la categoría b



```{r}
tbl = table(cred$V2, cred$V16)
tbl

chisq.test(tbl)

histograma(cred$V2)

boxplot(cred$V2)

shapiro.test(cred$V2)
```
El resultado del test chi es p-value = 0.1457 aunque con un warning. Parece que son variables dependientes.
Para el histograma se puede observar una mayor acumulación para valores más bajos de V2.
El boxplot muestra que todos los valores son atípicos.



```{r}
tbl = table(cred$V3, cred$V16)
tbl

chisq.test(tbl)

histograma(cred$V3)

boxplot(cred$V3)

shapiro.test(cred$V3)
```
El resultado del test Chi da también bien con un p-value = 0.1154 aunque con un warning. Parece que son variables dependientes.
En el histograma se aprecia una mayor acumulación para valores más bajos de V3.
El boxplot muestra que todos los valores son atípicos.


```{r}
tbl = table(cred$V4, cred$V16)
tbl

chisq.test(tbl)

ggplot(cred, aes(V4, fill=V16)) + geom_bar()
```
El resultado del test Chi para V4 es p-value = 2.011e-06 con lo que es un valor muy bajo.
En el gráfico de barras se aprecia una mayor frecuencia para la categoría u de V4.


```{r}
tbl = table(cred$V5, cred$V16)
tbl

chisq.test(tbl)

ggplot(cred, aes(V5, fill=V16)) + geom_bar()
```
El test Chi square para V5 es también muy malo: p-value = 2.011e-06
En el gráfico de barras se aprecia una mayor frecuencia en la categoría g de V5.

```{r}
tbl = table(cred$V6, cred$V16)
tbl

chisq.test(tbl)

ggplot(cred, aes(V6, fill=V16)) + geom_bar()
```
El test Chi para V6 nos da un p-valor muy bajo: 3.5e-15 warning incluido.
En el gráfico de barras puede verse que para la categoría c de V6 hay mayor frecuencia de aprobaciones y denegaciones.

```{r}
tbl = table(cred$V7, cred$V16)
tbl

chisq.test(tbl)

ggplot(cred, aes(V7, fill=V16)) + geom_bar()
```
El p-valor para V7 en chi square es muy bajo también: 3.625e-07
En el gráfico de barras se puede apreciar una mayor frecuencia de aprobaciones y denegaciones para la categoría v de V7


```{r}
tbl = table(cred$V8, cred$V16)
tbl

chisq.test(tbl)

histograma(cred$V8)

boxplot(cred$V8)

shapiro.test(cred$V8)
```
El chi square para V8 es malo: p-value = 6.17e-06
En el histograma se ve una mayor acumulación para valores bajos de V8.
El boxplot muestra que todos lo valores son atípicos.

```{r}
tbl = table(cred$V9, cred$V16)
tbl

chisq.test(tbl)

ggplot(cred, aes(V9, fill=V16)) + geom_bar()
```
Para V9 el chi square es muy malo: p-value < 2.2e-16
El gráfico de barras muestra una mayor frecuencia de denegaciones en la categoría f y una mayor frecuencia de aprobaciones para la categoría t de V9.

```{r}
tbl = table(cred$V10, cred$V16)
tbl

chisq.test(tbl)

ggplot(cred, aes(V10, fill=V16)) + geom_bar()
```
Para V10 el chi square es muy malo: p-value < 2.2e-16
En el gráfico de barras se observa una frecuencia mayor de denegaciones para la categoría f y una mayor frecuencia de aprobaciones para la categoría t.

```{r}
tbl = table(cred$V11, cred$V16)
tbl

chisq.test(tbl)

histograma(cred$V11)

boxplot(cred$V11)

shapiro.test(cred$V11)
```
Para V11 el chi square es muy malo: p-value < 2.2e-16
El histograma muestra una acumulación mayor para valores de V11 cercanos a 0.
El boxplot muestra que todos los valores son atípicos.


```{r}
tbl = table(cred$V12, cred$V16)
tbl

chisq.test(tbl)

ggplot(cred, aes(V12, fill=V16)) + geom_bar()
```
Para V12 el p-valor es muy bueno p-value = 0.4509. Parece que las variables son dependientes.
El gráfico de barras muestra una frecuencia de denegaciones ligeramente superior para la categoría f de V12.


```{r}
tbl = table(cred$V13, cred$V16)
tbl

chisq.test(tbl)

ggplot(cred, aes(V13, fill=V16)) + geom_bar()
```
Para V13 el chi square no es muy bueno: p-value = 0.01009
El gráfico de barras muestra una mayor frecuencia de aprobaciones y denegaciones para la categoría g de V13.


```{r}
tbl = table(cred$V14, cred$V16)
tbl

chisq.test(tbl)

ggplot(cred, aes(V14, fill=V16)) + geom_bar()
```
Para V14 el chi square no sale muy bien: p-value = 0.005489 
El gráfico de barras muestra frecuencias similares de categorías de V14.


```{r}
tbl = table(cred$V15, cred$V16)
tbl

chisq.test(tbl)

histograma(cred$V15)

boxplot(cred$V15)

shapiro.test(cred$V15)
```
Para V15 el chi square es malo: p-value = 0.0007081
El histograma para esta variable nos dice que hay mayor acumulación para V15 = 0.
El boxplot muestra que todos los valores son atípicos.

Conclusiones:
-Atendiendo al resultado de los test Chi Square, las variables V1, V2, V3 y V12 parece que son inddependientes y por tanto, las mejores para separar. 

-No parece que ninguna variable siga una distribución normal a juzgar por los histogramas presentados.



2. Prepara el dataset convenientemente e imputa los valores faltantes usando la librería `missForest`

```{r}
library(missForest)
cred.imp <- missForest(cred, maxiter = 20,ntree = 500,variablewise = T)
cred.imp$OOBerror
apply(cred,2,var,na.rm=TRUE)
apply(is.na(cred.imp$ximp),2,sum)
cred <- cred.imp$ximp
str(cred)
```

3. Divide el dataset tomando las primeras 590 instancias como train y las últimas 100 como test.

```{r}
cred$V16 <- as.numeric(cred$V16) - 1

X <- cred[,1:15]
dim(X)
y <- cred$V16
unique(y)


X_train <- X[1:590,]
y_train <- y[1:590]
X_test <- X[591:690,]
y_test <- y[591:690]
```

4. Entrena un modelo de regresión logística con regularización Ridge y Lasso en train seleccionando el que mejor **AUC** tenga. Da las métricas en test.

## Regresión logística con regularización Ridge

```{r}
X_train <- data.matrix(X_train)
X_test <- data.matrix(X_test)

library(glmnet)
set.seed(999)
cv.ridge <- cv.glmnet(X_train, y_train, family='binomial', alpha=0, parallel=TRUE, standardize=TRUE, type.measure='auc')
# Resultados
plot(cv.ridge)
#este es el mejor valor de lambda
cv.ridge$lambda.min
#este es el valor del error que se estima para ese valor lambda mínimo dado en MSE
max(cv.ridge$cvm)
```
Vemos los coeficientes
```{r}
coef(cv.ridge, s=cv.ridge$lambda.min)
```
Damos métricas en el test
```{r}
y_pred <- as.numeric(predict.glmnet(cv.ridge$glmnet.fit, newx=X_test, s=cv.ridge$lambda.min)>.5)
library(caret)
library(ggplot2)
library(lattice)
library(e1071)

confusionMatrix(as.factor(y_test), as.factor(y_pred), mode="everything")
```

## Regresión logística con regularización Lasso

```{r}
library(glmnet)
set.seed(999)
cv.lasso <- cv.glmnet(X_train, y_train, family='binomial', alpha=1, parallel=TRUE, standardize=TRUE, type.measure='auc')
# Resultados
plot(cv.lasso)
#este es el mejor valor de lambda
cv.lasso$lambda.min
#este es el valor del error que se estima para ese valor lambda mínimo dado en MSE
max(cv.lasso$cvm)
```

Vemos los coeficientes

```{r}
coef(cv.lasso, s=cv.lasso$lambda.min)
```

Damos métricas en el test

```{r}
y_pred <- as.numeric(predict.glmnet(cv.lasso$glmnet.fit, newx=X_test, s=cv.lasso$lambda.min)>.5)
library(caret)
library(ggplot2)
library(lattice)
library(e1071)
confusionMatrix(as.factor(y_test), as.factor(y_pred), mode="everything")
```

Conclusiones:
El recall de Lasso mejora

Seleccionaríamos el modelo Lasso por ser el mejor.

5. Aporta los *log odds* de las variables predictoras sobre la variable objetivo.

Buscamos el mejor modelo
```{r}
fit1 <- glm(V16~., data=cred, family=binomial)
fit0 <- glm(V16~1, data=cred, family=binomial)
library(MASS)
step <-stepAIC(fit0,direction="both",scope=list(upper=fit1,lower=fit0))
mod <- glm(V16 ~ V1 + V2 + V3 + V12, data=cred, family=binomial)
mod$coefficients
step$residuals
plot(predict(step),residuals(step))
coefficients(step)
# predecimos 1 si la probabilidad es mayor que 0.5 y 0 si es menor que 0.5 y comparamos
y_pred <- predict(step)>.5
head(y_pred)
head(cred$V16)
```

La matriz de confusión y las métricas de error se pueden calcular. Para obtener todas las que se han dado incluir la opción `mode="everything"` . Además se obtiene intervalo de confianza para el accuracy
```{r}
y_pred <- as.numeric(predict(mod, subset(cred,select = -V16 ), type="response")>.5)
y <- as.numeric(cred$V16)
# install.packages(c("e1071", "caret", "e1071")
library(caret)
library(ggplot2)
library(lattice)
library(e1071)

confusionMatrix(as.factor(y), as.factor(y_pred), mode="everything")

```

Observamos cómo influyen las variables en V16 a través de los coeficientes y los *log odds*
```{r}
coef(mod)
exp(coef(mod))
```

Conclusiones:

- Incrementar en una unidad V2 aumenta un 2% la probabilidad de concesión de crédito.

- Incrementar en una unidad V3 aumenta un 8% la probabilidad de concesión de crédito.

- Por cada unidad que se incrementa en V12t se incrementa un 13% la probabilidad de concesión de créditos

Obtenemos un intervalo de confianza para los valores de los coeficientes:
```{r}
exp(confint(mod))
```
6. Si por cada verdadero positivo ganamos 100e y por cada falso positivo perdemos 20e. ¿ Qué rentabilidad aporta aplicar este modelo?

Atendiendo a la matriz de confusión vemos que hay 109 verdaderos positivos y 198 falsos positivos. Haciendo el cálculo de la rentabilidad:
109TP * 100€ = 10900€ de ganancia
198FP * 20€ = 3960€ de pérdida

10900 - 3960 = 6940 euros de rentabilidad.
