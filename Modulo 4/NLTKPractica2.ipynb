{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acierto con unigramas: 87.65970871234029\n",
      "Acierto con bigramas: 89.42636311057363\n",
      "Acierto con trigramas: 89.01624691098375\n",
      "Acierto con HMMs: 89.88905831011094\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Importamos el corpus CESS del español, que es una colección de textos anotados\n",
    "from nltk.corpus import cess_esp\n",
    "\n",
    "\n",
    "# 2. Cargamos todas las frases anotadas del corpus CESS\n",
    "sents = cess_esp.tagged_sents()\n",
    "\n",
    "\n",
    "# 3. Creamos un conjunto de entrenamiento y otro de prueba\n",
    "#Metemos en el conjunto de entrenamiento el 90% de las frases, y el restante 10% en el conjunto de test\n",
    "training = []\n",
    "test = []\n",
    "for i in range(len(sents)):\n",
    "    if i % 10:\n",
    "        training.append(sents[i])\n",
    "    else:\n",
    "        test.append(sents[i])\n",
    "        \n",
    "        \n",
    "# 4. Creamos cuatro tipos distintos de analizadores morfológicos: \n",
    "# - Un tagger basado en unigramas: aprende de la estadística de cada palabra encontrada en el corpus CESS\n",
    "# - Otro basadoen bigramas: aprende de la estadística de una palabra y su palabra anterior\n",
    "# - Otro basado en trigramas: aprende a taggear una palabra basandose en la estadistica de la palabra y sus 2 anteriores\n",
    "# - Otro basado en Modelos Ocultos de Markov (en inglés Hidden Markov Models, HMM): es el modelo mas completo\n",
    "from nltk import UnigramTagger, BigramTagger, TrigramTagger\n",
    "from nltk.tag.hmm import HiddenMarkovModelTagger\n",
    "\n",
    "unigram_tagger = UnigramTagger(training)\n",
    "bigram_tagger = BigramTagger(training, backoff=unigram_tagger)\n",
    "trigram_tagger = TrigramTagger(training, backoff=unigram_tagger)\n",
    "hmm_tagger = HiddenMarkovModelTagger.train(training)\n",
    "\n",
    "\n",
    "\n",
    "# 5. Evaluamos sobre el conjunto de test que no usamos para el entrenamiento, para ver qué porcentaje de acierto hemos conseguido\n",
    "print ('Acierto con unigramas:',unigram_tagger.evaluate(test)*100)\n",
    "print ('Acierto con bigramas:',bigram_tagger.evaluate(test)*100)\n",
    "print ('Acierto con trigramas:',trigram_tagger.evaluate(test)*100)\n",
    "print ('Acierto con HMMs:',hmm_tagger.evaluate(test)*100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Los', 'da0mp0'), ('perros', 'ncmp000'), ('son', 'vsip3p0'), ('buenos', 'aq0mp0'), ('chuchetes', None)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 6. Probamos uno de nuestro taggers\n",
    "\n",
    "import nltk\n",
    "\n",
    "\n",
    "sentence = \"Los perros son buenos chuchetes\"\n",
    "\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "tagged = trigram_tagger.tag(tokens)\n",
    "\n",
    "\n",
    "print (tagged)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1.- Descargamos el tagger para el corpus en catalán (\"cess_cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import cess_cat\n",
    "sents = cess_cat.tagged_sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metemos en el conjunto de entrenamiento el 90% de las frases, y el restante 10% en el conjunto de test\n",
    "training_cat = []\n",
    "test_cat = []\n",
    "for i in range(len(sents)):\n",
    "    if i % 10:\n",
    "        training_cat.append(sents[i])\n",
    "    else:\n",
    "        test_cat.append(sents[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.- Analizar frase en Catalán (\"el president de la Generalitat ha tingut 4 chuchetes\"). En un primer momento, vamos a hacerlo individualizado:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.- Utilizando el tagger unigrama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAGGER UNIGRAMA CAT: [('el', 'da0ms0'), ('president', None), ('de', 'sps00'), ('la', 'da0fs0'), ('Generalitat', 'np0000o'), ('ha', 'vaip3s0'), ('tingut', None), ('4', 'Z'), ('chuchetes', None)]\n"
     ]
    }
   ],
   "source": [
    "sentence_cat = \"el president de la Generalitat ha tingut 4 chuchetes\"\n",
    "tokens_cat = nltk.word_tokenize(sentence_cat)\n",
    "tagged_cat = unigram_tagger.tag(tokens_cat)\n",
    "print (\"TAGGER UNIGRAMA CAT:\",tagged_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.- Utilizando el tagger bigrama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAGGER BIGRAMA CAT: [('el', 'da0ms0'), ('president', None), ('de', 'sps00'), ('la', 'da0fs0'), ('Generalitat', 'np0000o'), ('ha', 'vaip3s0'), ('tingut', None), ('4', 'Z'), ('chuchetes', None)]\n"
     ]
    }
   ],
   "source": [
    "sentence_cat = \"el president de la Generalitat ha tingut 4 chuchetes\"\n",
    "tokens_cat = nltk.word_tokenize(sentence_cat)\n",
    "tagged_cat = bigram_tagger.tag(tokens_cat)\n",
    "print (\"TAGGER BIGRAMA CAT:\",tagged_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.- Utilizando el tagger trigrama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAGGER TRIGRAMA CAT: [('el', 'da0ms0'), ('president', None), ('de', 'sps00'), ('la', 'da0fs0'), ('Generalitat', 'np0000o'), ('ha', 'vaip3s0'), ('tingut', None), ('4', 'Z'), ('chuchetes', None)]\n"
     ]
    }
   ],
   "source": [
    "sentence_cat = \"el president de la Generalitat ha tingut 4 chuchetes\"\n",
    "tokens_cat = nltk.word_tokenize(sentence_cat)\n",
    "tagged_cat = trigram_tagger.tag(tokens_cat)\n",
    "print (\"TAGGER TRIGRAMA CAT:\",tagged_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimos el % de acierto para cada una de las opciones de análisis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acierto con unigrama CATALAN: 41.38560961716003\n",
      "Acierto con bigrama CATALAN: 41.53489559802785\n",
      "Acierto con trigrama CATALAN: 41.460252607593944\n"
     ]
    }
   ],
   "source": [
    "print ('Acierto con unigrama CATALAN:', unigram_tagger.evaluate(test_cat)*100)\n",
    "print ('Acierto con bigrama CATALAN:', bigram_tagger.evaluate(test_cat)*100)\n",
    "print ('Acierto con trigrama CATALAN:', trigram_tagger.evaluate(test_cat)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.- Ahora realizamos el ejercicio siguiendo las pautas marcadas en el texto del mismo y que trasncribimos a continuación: \"El tagger entrenado (trigramTagger) en caso de fallar deberá devolver el resultado de un tagger de bigramas, que a su vez en caso de fallar devolverá uno de unigramas, que a su vez en caso de fallar deberá devolver el resultado de otro tagger. ¿Qué otro tagger? El que el alumno decida que es el más adecuado, tras leer el capitulo 5 del NLTK book\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos los datos de entrenamiento (90% del corpus seleccionado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acierto con método propuesto: 91.83444970437448\n",
      "TAGGER TRIGRAMA CAT: [('el', 'da0ms0'), ('president', 'ncms000'), ('de', 'sps00'), ('la', 'da0fs0'), ('Generalitat', 'np0000o'), ('ha', 'vaip3s0'), ('tingut', 'vmp00sm'), ('4', 'Z'), ('chuchetes', 'NLTK_FASHION')]\n"
     ]
    }
   ],
   "source": [
    "# - Para ello utilizaremos:\n",
    "# - Un tagger basado en unigramas: aprende de la estadística de cada palabra encontrada en el corpus CESS\n",
    "# - Otro basado en bigramas: aprende de la estadística de una palabra y su palabra anterior\n",
    "# - Otro basado en trigramas: aprende a taggear una palabra basandose en la estadistica de la palabra y sus 2 anteriores\n",
    "# - Otro basado en el modelo 'Default' que es el seleccionado entre los existentes en la lectura propuesta del capítulo 5 del NLTK book, este tagger puede utilizar patrones o una cadena para el elemento no encontrado (el que utilizaremos: 'NLTK_FASHION')\n",
    "from nltk import UnigramTagger, BigramTagger, TrigramTagger, DefaultTagger\n",
    "\n",
    "#Trabajamos con los datos de entrenamiento 'training_cat' que suponen el 90% del corpus\n",
    "default_tagger = DefaultTagger ('NLTK_FASHION')\n",
    "unigram_tagger = UnigramTagger(training_cat, backoff=default_tagger)\n",
    "bigram_tagger = BigramTagger(training_cat, backoff=unigram_tagger)\n",
    "trigram_tagger = TrigramTagger(training_cat, backoff=bigram_tagger)\n",
    "#Evaluamos sobre el conjunto 'test_cat' que no utilizamos para el entrenamiento:\n",
    "print ('Acierto con método propuesto:',trigram_tagger.evaluate (test_cat)*100)\n",
    "#Mostramos los resultados de sus tags para cada token de la frase analizada (sentence_cat):\n",
    "sentence_cat = \"el president de la Generalitat ha tingut 4 chuchetes\"\n",
    "tokens_cat = nltk.word_tokenize(sentence_cat)\n",
    "tagged_cat = trigram_tagger.tag(tokens_cat)\n",
    "print (\"TAGGER TRIGRAMA CAT:\",tagged_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, simplemente a modo informativo, utilizamos los datos de test 'test_cat' (10% de corpus seleccionado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acierto con método propuesto: 99.00017678602997\n",
      "TAGGER TRIGRAMA CAT: [('el', 'da0ms0'), ('president', 'ncms000'), ('de', 'sps00'), ('la', 'da0fs0'), ('Generalitat', 'np00000'), ('ha', 'vaip3s0'), ('tingut', 'vmp00sm'), ('4', 'Z'), ('chuchetes', 'NLTK_FASHION')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import UnigramTagger, BigramTagger, TrigramTagger, DefaultTagger\n",
    "\n",
    "default_tagger = DefaultTagger ('NLTK_FASHION')\n",
    "unigram_tagger = UnigramTagger(test_cat, backoff=default_tagger)\n",
    "bigram_tagger = BigramTagger(test_cat, backoff=unigram_tagger)\n",
    "trigram_tagger = TrigramTagger(test_cat, backoff=bigram_tagger)\n",
    "#Evaluamos sobre el propio conjunto 'test_cat':\n",
    "print ('Acierto con método propuesto:',trigram_tagger.evaluate (test_cat)*100)\n",
    "#Mostramos los resultados de sus tags para cada token de la frase analizada (sentence_cat):\n",
    "sentence_cat = \"el president de la Generalitat ha tingut 4 chuchetes\"\n",
    "tokens_cat = nltk.word_tokenize(sentence_cat)\n",
    "tagged_cat = trigram_tagger.tag(tokens_cat)\n",
    "print (\"TAGGER TRIGRAMA CAT:\",tagged_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.- Conclusión:\n",
    "- Resultado del tag 'chuchetes' obtenido en Castellano: 'ncmp000'\n",
    "- Resultado del tag 'chuchetes' obtenido en Catalán: 'NLTK_FASHION' (el sugerido como patrón para el método Default).\n",
    "Mediante el método en cadena propuesto en el ejercicio, se ha conseguido identificar correctamente cada token de la frase (cuestión que antes, cuando se analizaban los tagger por separado no obteníamos resultados por encima de un 41,53%)... pero 'chuchetes' sigue sin ser identificado..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
